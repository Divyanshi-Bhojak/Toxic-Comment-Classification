# Toxic-Comment-Classification

Online forums and social media platforms have provided individuals with the means to put forward their thoughts and freely express their opinion on various issues and incidents. A pre- trained model that gives the best accuracy to various user comments to combat the ongoing issue of online forum abuse. This project is focused on developing a series of neural network models. The goal is to find the strengths and weakness of different Deep Learning models on the text classification task.I developed the Neural Network models here is Convolutional Neural Network(CNN) with word and character embedding, Long Short Term Memory(LSTM) with word embedding and hybrid model which is a combination of CNN and LSTM with word embedding.

![image](https://user-images.githubusercontent.com/34389241/122652246-6c0db980-d15b-11eb-8823-85ee79694a29.png)


The dataset taken is kaggle's Toxic Comment Classification Challenge. 
Neural Network models developed can classify string comments based on their toxicity:

    toxic
    severe_toxic
    obscene
    threat
    insult
    identity_hate

